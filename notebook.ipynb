{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "# from transformers import AutoTokenizer\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm, trange\n",
    "import time\n",
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import re\n",
    "from pprint import pp, pformat as pf\n",
    "import demjson3 as demjson\n",
    "from IPython.display import display, Markdown, Latex, HTML\n",
    "\n",
    "from llm_fns.llm import llm_chat, UserMsg, SystemMsg\n",
    "from llm_fns.pmemo import memo, memo_cache_delete, memo_cache_delete_bytag\n",
    "from docker_env import DockerEnv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1, 2, 3'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# memo_cache_delete_bytag(tag=\"test0\")\n",
    "\n",
    "llm_chat(\n",
    "    \"test: count from 1 to 3\",\n",
    "    model=\"llama3-8b-8192\",\n",
    "    use_cache=True,\n",
    "    cache_tag=\"test0\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just a few drafts to try glan-like toplevel field taxonomy gen\n",
    "\n",
    "def STUDY_FIELD_A0(field):\n",
    "    return f\"I need to study {field}. List all subfields of {field} as well as all necessary foundational and applied knowledge and capabilities inherent to {field} in systematic & exhaustive manner. Use markdown headers to express hierarchical nature of the answer and format the constituents as markdown bullet lists.\"\n",
    "\n",
    "\n",
    "STUDY_FIELD_FOLLOWUP = \"\"\"\n",
    "Now step back for a second and analyze your answer to my previous request, providing constructive and unbiased criticism.\n",
    "Pay special attention to these aspects of your answer:\n",
    "1. Your answer should be exhaustive.\n",
    "2. It should not contain abridged parts such as \"etc.\", \"...\" - you should write everything explicitly, even if it will have to be fit in several messages.\n",
    "3. It should not include \"fluff\" points unnecessary for the student to achieve all capabilities expected from a master of this field.\n",
    "\"\"\".strip()\n",
    "\n",
    "STUDY_FIELD_FOLLOWUP_FINAL = \"Now output the final complete correct version of the list, integrating all relevant critcism and keeping the good parts of original answer intact\"\n",
    "\n",
    "\n",
    "def toplevel_syllabus(field, sysprompt=None, model=\"llama3-70b-8192\", **kwargs):\n",
    "    msgs = []\n",
    "\n",
    "    if sysprompt:\n",
    "        msgs.append(dict(role=\"system\", content=sysprompt))\n",
    "\n",
    "    msgs = [\n",
    "        dict(\n",
    "            role=\"user\",\n",
    "            content=STUDY_FIELD_A0(field),\n",
    "        ),\n",
    "    ]\n",
    "\n",
    "    followups = [STUDY_FIELD_FOLLOWUP, STUDY_FIELD_FOLLOWUP_FINAL]\n",
    "\n",
    "    for f in followups:\n",
    "        msgs.append(dict(role=\"user\", content=f))\n",
    "        next_msg = llm_chat(\n",
    "            msgs,\n",
    "            model=model,\n",
    "            **kwargs,\n",
    "        )\n",
    "        msgs.append(dict(role=\"assistant\", content=next_msg))\n",
    "\n",
    "    return msgs[-1][\"content\"]\n",
    "\n",
    "\n",
    "ret = toplevel_syllabus(\"software engineering\", use_cache=True, cache_tag=\"glan_dev_v0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What a great question!\n",
      "\n",
      "After conducting research and consulting with practitioners, I've developed a natural high-level taxonomy of the Python software engineering field from a practitioner's point of view. This taxonomy can serve as a foundation for designing an education program.\n",
      "\n",
      "**Level 1: Foundational Skills**\n",
      "\n",
      "* **Programming Fundamentals**: Understanding of Python syntax, data structures, control structures, functions, and object-oriented programming concepts.\n",
      "* **Development Tools**: Familiarity with integrated development environments (IDEs), text editors, and version control systems (e.g., Git).\n",
      "\n",
      "**Level 2: Core Competencies**\n",
      "\n",
      "* **Data Structures and Algorithms**: Knowledge of data structures (e.g., lists, dictionaries, sets) and algorithms (e.g., sorting, searching) in Python.\n",
      "* **Software Design Patterns**: Understanding of creational, structural, and behavioral design patterns in Python.\n",
      "* **Testing and Debugging**: Familiarity with unit testing, integration testing, and debugging techniques in Python.\n",
      "\n",
      "**Level 3: Domain Expertise**\n",
      "\n",
      "* **Web Development**: Knowledge of web frameworks (e.g., Django, Flask), templating engines (e.g., Jinja2), and web development best practices.\n",
      "* **Data Science and Analytics**: Understanding of popular libraries (e.g., NumPy, Pandas, scikit-learn) and concepts (e.g., machine learning, data visualization) in Python.\n",
      "* **Automation and Scripting**: Familiarity with automation tools (e.g., Ansible, Fabric) and scripting techniques in Python.\n",
      "\n",
      "**Level 4: Specialized Knowledge**\n",
      "\n",
      "* **Cloud and DevOps**: Knowledge of cloud platforms (e.g., AWS, GCP), containerization (e.g., Docker), and DevOps practices (e.g., CI/CD).\n",
      "* **Machine Learning and AI**: Understanding of deep learning frameworks (e.g., TensorFlow, PyTorch) and AI concepts (e.g., natural language processing, computer vision).\n",
      "* **Security and Compliance**: Familiarity with security best practices, threat modeling, and compliance frameworks (e.g., GDPR, HIPAA) in Python.\n",
      "\n",
      "**Level 5: Soft Skills and Professional Development**\n",
      "\n",
      "* **Communication and Collaboration**: Ability to communicate technical ideas, collaborate with teams, and manage stakeholders.\n",
      "* **Project Management and Agile Methodologies**: Understanding of project management frameworks (e.g., Scrum, Kanban) and agile development methodologies.\n",
      "* **Continuous Learning and Professional Development**: Commitment to staying up-to-date with industry trends, best practices, and emerging technologies.\n",
      "\n",
      "This taxonomy provides a comprehensive framework for designing an education program in Python software engineering. It covers the essential skills and knowledge required to become a proficient Python developer, from foundational programming skills to specialized knowledge in various domains.\n"
     ]
    }
   ],
   "source": [
    "def GEN_TAXONOMY(field):\n",
    "    return f\"\"\"\n",
    "Provide a natural high-level taxonomy of the {field} field suitable for designing an education program.\n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "def GEN_TAXONOMY_A1(field):\n",
    "    return f\"\"\"\n",
    "Provide a natural high-level taxonomy of the {field} field from practitioner\\'s point of view. The taxonomy should be suitable for designing an education program.\n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "def GEN_HANDS_ON_CURRICULUM_A1(field):\n",
    "    return f\"\"\"\n",
    "Design an educational software project\n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "print(\n",
    "    llm_chat(\n",
    "        [UserMsg(GEN_TAXONOMY_A1(\"python software engineering\"))],\n",
    "        model=\"llama3-70b-8192\",\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNER INPUT <<<\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "```json\n",
       "{\n",
       "  \"sources\": {\n",
       "    \"project.py\": \"import argparse\\nimport json\\nimport os\\n\\nTASKS_FILE = 'tasks.json'\\n\\ndef load_tasks():\\n    if os.path.exists(TASKS_FILE):\\n        with open(TASKS_FILE, 'r') as f:\\n            return json.load(f)\\n    return []\\n\\ndef save_tasks(tasks):\\n    with open(TASKS_FILE, 'w') as f:\\n        json.dump(tasks, f)\\n\\ndef add_task(task):\\n    tasks = load_tasks()\\n    tasks.append(task)\\n    save_tasks(tasks)\\n\\ndef list_tasks():\\n    tasks = load_tasks()\\n    for i, task in enumerate(tasks, 1):\\n        print(f\\\"{i}. {task}\\\")\\n\\ndef delete_task(index):\\n    tasks = load_tasks()\\n    try:\\n        del tasks[index - 1]\\n        save_tasks(tasks)\\n    except IndexError:\\n        print(\\\"Invalid task index\\\")\\n\\ndef main():\\n    parser = argparse.ArgumentParser(description='Task Manager')\\n    subparsers = parser.add_subparsers(dest='command')\\n\\n    add_parser = subparsers.add_parser('add', help='Add a new task')\\n    add_parser.add_argument('task', help='Task description')\\n\\n    list_parser = subparsers.add_parser('list', help='List all tasks')\\n\\n    delete_parser = subparsers.add_parser('delete', help='Delete a task')\\n    delete_parser.add_argument('index', type=int, help='Task index')\\n\\n    args = parser.parse_args()\\n\\n    if args.command == 'add':\\n        add_task(args.task)\\n    elif args.command == 'list':\\n        list_tasks()\\n    elif args.command == 'delete':\\n        delete_task(args.index)\\n\\nif __name__ == '__main__':\\n    main()\\n\"\n",
       "  },\n",
       "  \"tests\": {\n",
       "    \"test_project.py\": \"import unittest\\nfrom project import add_task, list_tasks, delete_task\\nimport json\\nimport os\\n\\nclass TestTaskManager(unittest.TestCase):\\n    def setUp(self):\\n        if os.path.exists('tasks.json'):\\n            os.remove('tasks.json')\\n\\n    def test_add_task(self):\\n        add_task('Task 1')\\n        with open('tasks.json', 'r') as f:\\n            tasks = json.load(f)\\n        self.assertEqual(tasks, ['Task 1'])\\n\\n    def test_list_tasks(self):\\n        add_task('Task 1')\\n        add_task('Task 2')\\n        output = io.StringIO()\\n        with redirect_stdout(output):\\n            list_tasks()\\n        self.assertIn('1. Task 1', output.getvalue())\\n        self.assertIn('2. Task 2', output.getvalue())\\n\\n    def test_delete_task(self):\\n        add_task('Task 1')\\n        add_task('Task 2')\\n        delete_task(1)\\n        with open('tasks.json', 'r') as f:\\n            tasks = json.load(f)\\n        self.assertEqual(tasks, ['Task 2'])\\n\\nif __name__ == '__main__':\\n    unittest.main()\\n\"\n",
       "  }\n",
       "}\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNER OUTPUT >>>\n",
      "{'installers': [], 'tests': {'pass': False, 'output': 'test_add_task (test_project.TestTaskManager.test_add_task) ... ok\\ntest_delete_task (test_project.TestTaskManager.test_delete_task) ... ok\\ntest_list_tasks (test_project.TestTaskManager.test_list_tasks) ... ERROR\\n\\n======================================================================\\nERROR: test_list_tasks (test_project.TestTaskManager.test_list_tasks)\\n----------------------------------------------------------------------\\nTraceback (most recent call last):\\n  File \"/test_project.py\", line 20, in test_list_tasks\\n    output = io.StringIO()\\n             ^^\\nNameError: name \\'io\\' is not defined\\n\\n----------------------------------------------------------------------\\nRan 3 tests in 0.002s\\n\\nFAILED (errors=1)\\n'}}\n"
     ]
    }
   ],
   "source": [
    "def GEN_EDU_PROBLEMS_A0(lang=\"python\", ext=\"py\", comment=\"#\", project_kind=\"cli tool\"):\n",
    "    return f\"\"\"\n",
    "    As a programming mentor create a self-contained {lang} {project_kind} project and then use it as a base to create an educational programming/software engineer task that will require the student to read and understand the project and make 1-3 reasoning steps to solve correctly. You should output:\n",
    "    1. A concise plan for this task which starts from the core competencies and concepts the student will be required to master to pass.\n",
    "    2. A source code for a standalone {lang} {project_kind} project as a single {lang} file.\n",
    "    3. An educational programming/swe task expressed in English which should require the student some mastery over {lang}, the project and general software engineering skills to solve.\n",
    "    4. A unit test named test_task.{ext} that can be used to automatically verify the student has solved the task - it should fail in the current state and it should pass when the task is solved.\n",
    "\n",
    "    When you output a {lang} source code file ALWAYS output the the correct filename I should save it into like this: ```{lang}\\n{comment} test_task.{ext}\n",
    "    Code carefully ensuring the {lang} files and unittests you code are correct and do not contain any bugs preventing the project from being executed.\n",
    "    Now start with the plan and then execute the rest of my task:\n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "def GEN_EDU_PROJECT_A0(lang=\"python\", project_file=\"project.py\", ext=\"py\", comment=\"#\", project_kind=\"cli app\"):\n",
    "    return f\"\"\"\n",
    "    As a programming mentor create a self-contained {lang} {project_kind} project which we will then use as a base to create educational programming tasks. Ensure the project is correct, complete and is interesting and non-trivial enough to provide educational value to the students who will work on it. You should output:\n",
    "    1. A concise plan for this task which starts from the core competencies and concepts the student will be required to master to work on this project.\n",
    "    2. A source code file named {project_file} containing a standalone {lang} {project_kind} project implementation as a single {lang} file.\n",
    "    3. A set of unit tests named test_project.{ext} that reliably covers the essential functionality of the project. Pay attention to unit test correctness as we will later use these tests to automatically verify students\\' performance.\n",
    "    4. If the project requires {lang} libraries not contained in {lang} standard library to work you have to provide a shell script named install.sh which should install the necessary libraries. You should not provide install.sh script otherwise.\n",
    "\n",
    "    # Important notes!\n",
    "    When you output a source code file you have to ALWAYS prefix the codeblock with markdown header like this: ### FILE: <complete_file_name_here>. I will save the codeblock content into the appropriately named files.\n",
    "\n",
    "    Code carefully ensuring the {lang} files and unittests you code are correct and do not contain any bugs preventing the project from being executed.\n",
    "\n",
    "    Now start with the plan and then execute the rest of my task:\n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "ret = llm_chat(\n",
    "    GEN_EDU_PROJECT_A0(), model=\"llama3-70b-8192\", use_cache=True, cache_tag=\"prtask_v0\"\n",
    ")\n",
    "\n",
    "# display(Markdown(ret))\n",
    "\n",
    "def extract_codeblocks(text, require_name=True):\n",
    "    \"\"\"\n",
    "    Extract Markdown code blocks from a string\n",
    "\n",
    "    :param text: String containing Markdown code\n",
    "    :param require_name: If True, also match the filename prefix (# FILE: <filename>\\n)\n",
    "    :return: List of extracted code blocks (and filenames if require_name is True)\n",
    "    \"\"\"\n",
    "    if require_name:\n",
    "        codeblock_pattern = r\"#+\\s+FILE:\\s*([^\\n]*)\\s*\\n*```([^\\n]*)?\\n([^```]+)```\"\n",
    "        codeblocks = re.findall(codeblock_pattern, text)\n",
    "        codeblocks = [\n",
    "            (code, filename.strip(), lang) for filename, lang, code in codeblocks\n",
    "        ]\n",
    "    else:\n",
    "        codeblock_pattern = r\"```([^\\n]*)?\\n([^```]+)```\"\n",
    "        codeblocks = re.findall(codeblock_pattern, text, re.DOTALL)\n",
    "        codeblocks = [code for code in codeblocks]\n",
    "    return codeblocks\n",
    "\n",
    "\n",
    "def print_code(src, language=\"\"):\n",
    "    _src = src.rstrip(\"\\n\")\n",
    "    display(Markdown(f\"```{language}\\n{_src}\\n```\"))\n",
    "\n",
    "def debug_dict(d, maxlen=80):\n",
    "    return {k: str(v)[:maxlen] + \"...\" if len(str(v)) > maxlen else str(v) for k, v in d.items()}\n",
    "\n",
    "def print_json(src, shorten=False, maxlen=80):\n",
    "    if shorten:\n",
    "        src = debug_dict(src, maxlen=maxlen)\n",
    "    print_code(json.dumps(src, indent=2), language=\"json\")\n",
    "\n",
    "def parse_files(txt, require_filename=True, verbose=False):\n",
    "    cbs = extract_codeblocks(txt)\n",
    "    ret = {}\n",
    "    for cb in cbs:\n",
    "        if require_filename:\n",
    "            assert isinstance(cb[1], str)\n",
    "        \n",
    "        ret[cb[1]] = cb[0]\n",
    "        \n",
    "        if verbose:\n",
    "            print(\"-\" * 80)\n",
    "            print(f\"FILE: {cb[1]}\")\n",
    "            print(\"-\" * 80)\n",
    "            print_code(cb[0], language=cb[2])\n",
    "    \n",
    "    return ret\n",
    "\n",
    "\n",
    "def _verify_project(\n",
    "    sources, tests, installers=None, async_mode=False, start_cmd=None, stop_cmd=None\n",
    "):\n",
    "    denv = DockerEnv()\n",
    "\n",
    "    # Copy source files into the Docker environment\n",
    "    denv.copy_files(file_dict=sources)\n",
    "\n",
    "    # Copy test files into the Docker environment\n",
    "    denv.copy_files(file_dict=tests)\n",
    "\n",
    "    # Run installers\n",
    "    installer_outputs = []\n",
    "    if installers and len(installers):\n",
    "        for installer_path, installer_content in installers.items():\n",
    "            denv.copy_files(file_dict={installer_path: installer_content})\n",
    "            installer_output, installer_exit_code = denv.run_command(\n",
    "                f\"bash {installer_path}\"\n",
    "            )\n",
    "            installer_outputs.append(\n",
    "                {\n",
    "                    \"path\": installer_path,\n",
    "                    \"output\": installer_output,\n",
    "                    \"status\": \"OK\" if installer_exit_code == 0 else \"FAILED\",\n",
    "                }\n",
    "            )\n",
    "    \n",
    "    tests_passed = False\n",
    "\n",
    "    if async_mode:\n",
    "        # Start the app\n",
    "        start_output, start_exit_code = denv.run_command(start_cmd)\n",
    "        if start_exit_code != 0:\n",
    "            print(\"Error starting the app: \", start_output)\n",
    "            denv.cleanup()\n",
    "            return\n",
    "\n",
    "        # Run the tests\n",
    "        test_output, test_exit_code = denv.run_command(\"python -m unittest discover -v\")\n",
    "        tests_passed = test_exit_code == 0\n",
    "\n",
    "        # Stop the app\n",
    "        stop_output, stop_exit_code = denv.run_command(stop_cmd)\n",
    "\n",
    "    else:\n",
    "        # Run the tests\n",
    "        test_output, test_exit_code = denv.run_command(\"python -m unittest discover -v\")\n",
    "        tests_passed = test_exit_code == 0\n",
    "\n",
    "    # Create a JSON log with the results\n",
    "    log = {\n",
    "        \"installers\": installer_outputs,\n",
    "        \"tests\": {\"pass\": tests_passed, \"output\": test_output},\n",
    "    }\n",
    "\n",
    "    if async_mode:\n",
    "        log[\"app\"] = {\n",
    "            \"start\": {\n",
    "                \"output\": start_output,\n",
    "                \"status\": \"OK\" if start_exit_code == 0 else \"FAILED\",\n",
    "            },\n",
    "            \"stop\": {\n",
    "                \"output\": stop_output,\n",
    "                \"status\": \"OK\" if stop_exit_code == 0 else \"FAILED\",\n",
    "            },\n",
    "        }\n",
    "\n",
    "    # Clean up\n",
    "    del denv\n",
    "\n",
    "    return tests_passed, log\n",
    "\n",
    "# print(ret)\n",
    "# parse_files(ret)\n",
    "\n",
    "def verify_gen_project(generated_text, project_file=\"project.py\", test_file=\"test_project.py\", install_file=\"install.sh\", verbose=False):\n",
    "    files = parse_files(ret)\n",
    "    runner_kwargs={}\n",
    "    if (project_file in files and test_file in files):\n",
    "        if install_file in files:\n",
    "            runner_kwargs[\"installers\"] = {install_file: files[install_file]}\n",
    "        runner_kwargs[\"sources\"]={project_file: files[project_file]}\n",
    "        runner_kwargs[\"tests\"]={test_file: files[test_file]}\n",
    "\n",
    "        if verbose:\n",
    "            print(\"RUNNER INPUT <<<\")\n",
    "            print_json(runner_kwargs)\n",
    "        \n",
    "        success, logs = _verify_project(**runner_kwargs)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"RUNNER OUTPUT >>>\")\n",
    "            print(logs)\n",
    "\n",
    "verify_gen_project(parse_files(ret), verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
